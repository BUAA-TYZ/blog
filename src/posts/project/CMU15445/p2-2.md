---
date: 2024-08-04
category:
  - 数据库
tag:
  - C++
footer: 凉了的馒头
---

# CMU15445 (Spring 2023) Project #2 - B+Tree Checkpoint #2


## 前言  

承接上文

上个周末抽空完成了 Checkpoint2 ，做的过程大体上还是比较愉快的。得益于我一直当多线程做的，从一开始就考虑并发问题，所以最后最难的 Task 4 虽然还是出现了 bug 但并没有浪费我太多的时间。

> PS: 今天上网搜索 CMU15445 的时候发现 CMU15445 Fall2023 的官网都已经有了，顿时心头一紧!

### 言归正传：  

这个 Checkpoint 我们要完成的是 B+ Tree 的删除逻辑 迭代器 以及 最难的并发部分，本文主要聚焦于三个部分：

- 删除过程的细节处理
- 迭代器的设计思路
- 各个部分遇到的各种 bug

最后还会谈一谈 debug 的心得


## 一、三个 Task  

### Task #2b - B+Tree Deletions  

对于删除，我没有使用书上的伪代码，依旧是自己用迭代实现的，当然书上的递归实现确实比我的优雅很多了。这一部分，关键是理清每一个步骤要用到哪些页，以及哪几个键/值，能清晰地有一个认识，这样做的时候才能减少犯错。

对于叶节点，它的 Merge 和 Borrow 都是显然的就略过了，因为它的所有键值对都是有效的

下面用文字阐述一下 中间节点的 Merge 和 Borrow 过程。

我们考虑三个节点

1. 被删除了一个键而需要 Merge/Borrow 的中间节点 `internal_page`
2. 它的父亲节点 `parent_page`
3. 它的兄弟节点 `sibling_page`

其中两个子节点在父亲节点中分别是两个相邻的 Value，这两个 Value 中间夹着一个 Key，我们称它为 `delete_key` 如下所示

Parent page 内部结构： `... | internal_page_id | delete_key | sibling_page_id | ...` 

以上就是用到的所有变量了

**Merge**

* 兄弟节点在中间节点左边

我们合并中间节点，即把中间节点的所有键值对都加到兄弟节点的后面。但是，中间节点的第一个 Key 要特殊处理，因为它是一个无效的 Key，我们用 delete\_key 替代之即可，随后删除中间节点。

```cpp
sibling_page->Merge(internal_page, delete_key);
internal_page_guard.Drop();
BUSTUB_ENSURE(bpm_->DeletePage(current_page_id), "Delete page failure");

```

* 兄弟节点在中间节点右边：一样的步骤，反过来即可

**例子**

**我们不关注绿色的叶子节点，只需关注上面三个红色的中间节点即可。**

![](/assets/posts/CMU15445-Refs/p2-2/1.png)  

我们考虑 P=3 的页面，当我们删除 3 后，发现当前节点 size = 1 < min\_size，兄弟节点 size =2，1+2<=max\_size，触发 Merge。

结合上面，internal\_page就是 P=3，sibling\_page就是 P=6，parent\_page 就是 P = 7，且 **delete\_key = 5**，于是我们先删除 P=3 中的 3 ，然后把兄弟节点的第一个 key 填充为 delete\_key 也就是 5，随后把兄弟节点全部加入到 P=3 的后面，于是就成了下图：

![](/assets/posts/CMU15445-Refs/p2-2/2.png)  

  


Merge 的时候我们不考虑 `parent_page` 因为它会迭代到下一轮被更新，删除并没有结束。而下面的 Borrow 则需要考虑 `parent_page` 因为 Borrow 完流程就结束了我们需要及时更新父节点。

**Borrow**

- 兄弟节点在中间节点左边

我们把兄弟节点的最后一个键值对插入到中间节点的开头，但注意原先中间节点的第一个键是无效的，插入结束后无效的键也就被推到了第二个键的位置。我们需要把它替换为 delete\_key，随后我们更新父节点的 delete\_key 为从兄弟节点借的那个键值对中的 key

```cpp
int delete_index = sibling_page->GetSize() - 1;
internal_page->InsertAtBegin(sibling_page->KeyAt(delete_index),
                             sibling_page->ValueAt(delete_index));
internal_page->SetKeyValueAt(1, delete_key, internal_page->ValueAt(1));
sibling_page->DecreaseSize(1);
parent_page->SetKeyValueAt(key_index, internal_page->KeyAt(0), parent_page->ValueAt(key_index));

```

  
- 兄弟节点在中间节点右边

我们需要往中间节点插入一个键值对，它应该是兄弟节点的第一个键值对，但不要忘了第一个键是无效的，所以这里插入的键我们要换为 delete\_key，插入的值不变。 随后我们更新父节点的 delete\_key 为兄弟节点的第一个键即可（因为这里的第一个键是刚刚被推过来的第二个键，所以是有效的）

**例子**

**我们不关注绿色的叶子节点，只需关注上面三个红色的中间节点即可。**

![](/assets/posts/CMU15445-Refs/p2-2/3.png)  

删除 P=3 中的 1 ，internal\_page : P=3，sibling\_page : P=13，parent\_page : P=10，**delete\_key=3**

size=1，兄弟节点 size=3， 1+3>max\_size，于是触发 Borrow。

P=3 先删除 1 ，然后往右借 P=13 的第一个键值对，第一个键改为 delete\_key，值不变，于是变成下图

![](/assets/posts/CMU15445-Refs/p2-2/4.png)  


这个部分遇到的 bug 是我一开始没有对 根节点 进行特判，因为 **根节点 的 size 是可以小于 min\_size 的**，我们需要特殊考虑它。这里书上的伪代码我看了一下也是没有考虑，应该算是小瑕疵了。

下面顺手附上书中的伪代码：其中加入了对根节点的特判

![](/assets/posts/CMU15445-Refs/p2-2/5.png)  

---

### Task #3 - An Iterator for Leaf Scans  

迭代器部分不涉及并发相关，所以不用额外考虑过多，它的用途是在**树建好**的情况下遍历所有的键值对，是只读的。

拿到空空的一个头文件，我相信不少人都会跟我一样先懵一下。所以这里介绍一下我写迭代器的心路历程。首先，一个迭代器指向的是一个 键值对，所以我们需要一个 `leaf_page` 的指针和 一个 `pair_index_` 来表示键值对在 叶节点中的位置。

随后我们考虑 `operator++` 这个操作符，我们需要将 `leaf_page` 切换到下一个 叶节点 的第一个键值对上，所以我们无疑需要 `bpm_` ，不然我们从哪儿取出新的一页呢？

最后考虑 `operator==`这个操作符，我们如何比较两个相同的迭代器？首先肯定必须是同一个 `leaf_page`，诚然我们可以比较指针来确定是否是同一个 `leaf_page`，因为**树已经建好并且内存是动态分配的，**指针应该不会变化。但这个行为是**很危险**的（我写 Project 1 中就利用了红黑树的节点指针不变的特点而没有用 id 最后硬着头皮弄了好久才解决了所有 bug），所以这里我们额外使用一个变量 `leaf_page_id` 记录当前 `leaf_page` 的 id。比较 id 来确定是否是同一个叶节点。随后比较它们的在叶节点中的位置即可。

同时，我们引入 `guard` 包裹指针，最后设计如下：

![](/assets/posts/CMU15445-Refs/p2-2/6.png)  

---

### Task #4 - Concurrent Index  

这部分是并发，策略课上已经讲的很清楚了。这里的关键是 debug。我们可以用打 log 的方式窥探每个线程的操作。Bustub 给我们提供了 log 工具。

![](/assets/posts/CMU15445-Refs/p2-2/7.png)  

BUSTUB自带的debug工具

  
对于 log 不熟悉的同学，推荐学习谷歌家的 glog ，对一个好的 log 长什么样有个清楚的认识，并结合 cmake 写几个小的程序跑起来看看

[glog 官方介绍](https://github.com/google/glog)

下面讲我的多线程遇到的 bug ，总结起来就是一个教训：不要先写乐观锁

我为了方便，就先写了乐观锁，乐观锁本身没问题，我错的地方在于我没有将乐观锁当成独立的一部分，最后成为了 下面我阐述一下当时的 bug

```
下面是我的插入函数的流程

{
    // 乐观锁部分
    拿到叶节点
    if (值在叶中已经存在) {
        return false;
    }
    if (叶节点满) {
        退出乐观锁部分
    }
}


// 悲观锁部分
...
因为上面考虑了值已经存在的情况，所以这里我就没考虑了，最终造成错误。 <- 不行！！

```

我们考虑三个线程，

- thread1 : Insert 1
- thread2 : Insert 1
- thread3 : Remove 2

假设：对应的叶节点是满的并且 1 和 2 最终会到同一个叶节点，叶节点中没有 1 有 2

thread1 先走上面的乐观部分，发现值不存在并且叶节点满，于是退出乐观部分，释放了叶节点的写锁，准备从头开始悲观插入 1 。这时 thread3 启动，因为叶节点对于删除它是安全的，它直接乐观的删除了 2，再次释放该叶节点的写锁。然后 thread2 启动，因为原先满的节点刚刚被删除了一个，所以现在是可以乐观插入的！于是这个节点现在有了 1 。综上，对于现在的 thread1 来说它在悲观锁部分就出现了**逻辑分裂**，上面刚刚判断过 1 不存在，突然 1 就存在了，所以仍然需要考虑 **值在叶中已经存在** 的情况，如果不考虑，仍然插入 1 无疑会导致节点分裂并出现两个重复的键。

发现了问题，解决方法就很简单了，在悲观部分中也考虑一下即可，或者我们在释放叶节点写锁之前，拿住 `header_page` 的锁，原子地进入悲观部分，这样就不会有逻辑分裂了。

总的来说，多线程是很难模拟的。我基于同一个节点，**已经拿了写锁**并判断过这一事实，自以为已经很安全了，于是悲观部分就没有再次判断，最终导致错误，这也正应了我前文结尾写的 **要考虑全面。**

**需知：就算有的逻辑判断觉得没必要，也不妨写出来，因为多线程的运行确实难以预测，我能相信的只有拿着锁的时候。**


## 二、debug 心得  

（这里的 心得 不是技术向的）上面那个 bug 花了我很大功夫打上 log 来排查，并且从打完 log 到发现 bug，解释 bug 修改 bug 又经历了一个痛苦的过程。甚至连定位错误都是一种奢望，我的程序最终是线上报了 内存泄露 的错误。（错误提示不仅一点用都没有，还一度把我引入一个错误的思路上，并且因为拿不到测试样例，我始终复现不出错误）

最终，唯有靠着不断的思考来发现 bug ，从下午一点改到晚上八点，大概花了五个多小时最终找到问题所在。心得就是我觉得不应该耗费太长时间耗在那儿，找一会 bug 就休息休息，放松一下，恢复一下精力。长时间找 bug 真的很容易发呆... 同时，如果长时间没找到 bug 也不要太过沮丧，多线程的 bug 本来就是一个很深的坑，多锻炼锻炼吃吃苦也未必是坏事，毕竟**所有人都是这样过来的**，不要妄自菲薄！


## 最后  

很高兴实现了 B+ Tree ，想想这好像是我实现过最复杂的数据结构了哈哈，没有手撸过红黑树，AVL 应该没有这个复杂吧，而且这个还是多线程的。

最后的 QPS 并不高，但锁的争用程度还是比较高，在 3.2 上下，快摸到 3.5 的上限了

而且有意思的是，我尝试加了大锁后测出的单线程版本的 QPS 和多线程的只差了几千，有时间再研究一下测试函数吧！

（截至到 2023.08.04 共有 118 个人通过这个部分，并没有想象的人多）

![](/assets/posts/CMU15445-Refs/p2-2/8.png)  