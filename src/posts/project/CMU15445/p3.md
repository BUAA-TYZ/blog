---
date: 2024-09-22
category:
  - 数据库
tag:
  - C++
footer: 凉了的馒头
---

# CMU15445 (Spring 2023) Project #3 - Query Execution


## 前言  

这次的 Project 要求我们实现几个简单的 Executor ，写完这个 Project 我们就可以在 bustub-shell 中检验自己的成果了。

[官方文档](https://15445.courses.cs.cmu.edu/spring2023/project3/)

这个项目要求阅读不少的代码，所以本文还会穿插介绍一些 Clion 的快捷键。

**2023.08.25** 将与项目无关的知识单独整理到最后

**2023.09.08** 完成所有优化


## 理解  

我们首先要从宏观上认识这一整个项目

![](/assets/posts/CMU15445-Refs/p3/1.png)  

我们说 SQL 是一种语言，它将一系列数据库的底层操作抽象成我们能理解的东西。那么正如 C 语言要经过 预编译->编译->汇编->链接 这四个阶段，SQL 语言也要经过一个类似的过程。

如图，一条写出的 SQL 语句，首先经过 **PARSER** 生成 AST 抽象语法树，再由 **BINDER** 将 AST 上的每个节点与一个数据库实体绑定，随后 **PLANNER** 生成一个初步的查询计划，**OPTIMIZER** 对初步的查询计划进行优化，使其成本更低，最后这个计划被送入一堆 **Executors** 中进行执行。

或许有些抽象，我们可以看一个例子：

![](/assets/posts/CMU15445-Refs/p3/2.png)  

我们可以清晰的看到每个阶段完成了什么，比如：**PLANNER** 生成的初步计划使用的是效率最低的 NestedLoopJoin (NLJ)，经过优化后计划变为了效率更高的 HashJoin。最终生成的计划如下：

![](/assets/posts/CMU15445-Refs/p3/3.png)  

图中的每一个圆都对应了一个 Executor

而对于每个 Executor，bustub 采用了迭代器模型(火山模型)：一个 Executor 执行一次 `Next()` 就会返回一条符合对应条件的 Tuple。

![](/assets/posts/CMU15445-Refs/p3/4.png)  


### 分析Projection\_executor  

官方文档中提到了，Projection\_executor 已经由官方提供给我们了，所以我们可以借助其快速上手。

![](/assets/posts/CMU15445-Refs/p3/5.png)  

结合上面的例子，这里的 `child_executor_` 就是上面的 HashJoin，我们调用 `child_executor_->Next(...)`从 HashJoin 中拿到一个 Tuple，随后对其中的属性进行投影。

* 如何取出 Tuple 中某一个属性的值：拿到对应的 expr ，随后使用 `expr->Evalute(&tuple, ...)` 即可，这个在之后也会用到。
* 如何构造出一个 Tuple：构造一个 `std::vector<Value>` 储存每一个属性的值

至此，我们应该对迭代器模型有了更深刻的认识，最上层的节点调用 `Next()`，而其中又会调用下一层节点的 `Next()`，就像找下一层节点要 Tuple 一样，以此类推最终得出结果。这样的过程犹如流水线一般，从上而下依次索取 Tuple

![](/assets/posts/CMU15445-Refs/p3/6.png)  


## 实现  

### Task #1 - Access Method Executors  

这部分大致要掌握几个类 ：`Catalog` `TableHeap`

比如我们需要表的元信息和表的索引时，我们先通过上下文 `exec_ctx_`：拿到 Catalog ，其中有所有表和索引的元信息，随后按需获取

![](/assets/posts/CMU15445-Refs/p3/7.png)  

> 如果你使用的是 Clion ，只需点击一下 `GetCatalog()` ，随后按 Ctrl+Alt+b 就可一键切换到定义处，非常方便 （可能需要先解除 Vim 的快捷键）。包括头文件，变量等等，都可以这样一键到达。

而 TableHeap 类，其中则包括了所有更新元组，读取元组的操作。

这里建议做的时候回顾课件 lecture#03 -> Heap File organization/ Page layout/ Tuple layout

- 对于删除操作，我们并不真正删除一个 Tuple ，而是通过 `UpdateTupleMeta()` 标注其 MetaData 中的 is\_deleted 变量
- **对于更新操作，我们从 Next 中只能拿到要删除的 Tuple ，那新的 Tuple 从哪儿拿呢？**

![](/assets/posts/CMU15445-Refs/p3/8.png)  

update\_plan比别的多了一个成员变量,答案就来自于 update\_plan.h 中的 `target_expressions_`。

并且正如我上面在分析投影提到的，我们通过 Evaluate 拿到一个 Tuple 的一个属性的值，所以可以如下拿到新的 Tuple

![](/assets/posts/CMU15445-Refs/p3/9.png)  

而更新索引的操作则涉及到我们之前项目中写过的 B+Tree Index，从项目介绍中可以大致了解 bustub 的索引类型：

> The type of the index object in the plan will always be `BPlusTreeIndexForTwoIntegerColumn` in this project. You can safely cast it and store it in the executor object:

```cpp
tree_ = dynamic_cast<BPlusTreeIndexForTwoIntegerColumn *>(index_info_->index_.get())

//using BPlusTreeIndexForTwoIntegerColumn = BPlusTreeIndex<IntegerKeyType, IntegerValueType, IntegerComparatorType>; 

```

可以看到我们拿到索引并转型成 BPlusTreeIndex 类型，BplusTreeIndex 其实就是对我们在 Project2 中写的 BPlusTree 的一个包装。

![](/assets/posts/CMU15445-Refs/p3/10.png)  

注意它的三个迭代器用法正好对应我们在 Project2 中所写的那三个迭代器函数，所以我们在这要做的就是调用 `tree_->GetBeginIterator()`，(当然后续优化这个会被换掉)，对每个迭代器进行解引用会得到 MappingType，如下所示

![](/assets/posts/CMU15445-Refs/p3/11.png)  

随后就可以拿到 RID 了，根据 RID 就可以拿到 Tuple 了：`table_info_->table_->GetTuple(*rid)`

分享一下我的构造函数以帮助同学上手。

![](/assets/posts/CMU15445-Refs/p3/12.png)  

这里的 index\_scan 实际上就是为了后续 OrderBy 规则的，因为 index\_scan 得到的数据天生是排好序的。而在优化中，我们可以进一步完善，使其起到过滤的作用。

### Task #2 - Aggregation & Join Executors  

如果你也像我一样已经忘了很多数据库操作，这儿有一个网站可以快速帮你回忆起来

[SQL Tutorial](https://www.w3schools.com/sql/default.asp)

对于 Aggregation，并没有太多好说的，唯一需要注意的就是当为空表的时候，我们（或许）需要往哈希表中插入一个空键值对。

对于 NLJ，这个是不太好写的，尽管看上去很简单：

![](/assets/posts/CMU15445-Refs/p3/13.png)  

难点在于我们一次 Next 只返回一个 Tuple，如何让这一次的 Next 接着上一次的 Next 继续而不是重头再来？

我这里手动记录了上下文：**当前的 Outer\_tuple** 对应上图的小写 r 以及**所有的 Inner\_tuples** 对应上图的大写 S ，以及**当前遍历到的小写 s 的序号**，这样每一次 Next 只需递增这个序号即可。

并且每调用一次 Outer 的 Next 要记得对 Inner 的进行一次 Init

对于 HashJoin，我们直接对 Aggregation 中的哈希表进行模仿即可：

![](/assets/posts/CMU15445-Refs/p3/14.png)  

翻译完毕之后就可以使用了，细节均可参考 Aggregation 中的那个哈希表。

需要注意的是 HashJoin 是 **Pipeline Breaker，** 这意味着它需要在 Init 阶段就建立哈希表并完成探测，后面的 Sort 也是这样，在 Init 阶段就得到所有结果。


对于如何优化 NLJ 为 HashJoin，我们可以借鉴 `nlj_as_index_join.cpp`。

![](/assets/posts/CMU15445-Refs/p3/15.png)  

首先，我们递归的对子节点运用这些规则，这是因为对于一个嵌套的 Join ，我们需要对每个 Join 都进行优化。

随后，我们将其转化为 nlj\_plan，并提取谓词 Predicate 出来。

对于这次的 Project 我们需要完成两种等值 Join

1. `<column_expr> = <column_expr>` 比如 test\_1.colA = test\_2.colA

这种只需如图中一样提取出左右两边 Tuple 就好了，随后构造 Plan 返回

2. `<column_expr> = <column_expr>` and `<column_expr> = <column_expr>`

这种需要阅读 `logic_expression.h`，最终也是差不多的步骤

我们也可以借鉴学习 2022 年的是怎么写的。

![](/assets/posts/CMU15445-Refs/p3/16.png)  

### Task #3 -Sort + Limit Executors and Top-N Optimization  

这里的 sort 和 limit 应该是很简单了

而 topn 需要对 C++ 的 prority\_queue 有一定了解，它是一个大根堆，我们需要这样初始化它：

```cpp
std::priority_queue<Tuple, std::vector<Tuple>, CompareRule> topn_res(
      CompareRule(plan_->GetOrderBy(), child_executor_->GetOutputSchema()));

```

其中 CompareRule 是我们自己编写的类，重载了 `operator()` 运算符

这里将 Sort 和 Limit 优化成 Topn 也不难，明确这两个节点的顺序：Sort 是 Limit 的 child\_executor 即可。


## 在 Clion 上使用 git  

最近尝试了一下 Clion 上的 git ，就再也不想用命令行了！我们首先在 Clion 上授权登陆 github 账号

随后在上方点击 Git，点击显示 Git 日志，我们就可以在下面详细的看到每一条提交记录了，随便点击一条，右边就会显示出这次提交修改的文件，点击文件，就能看到这次提交作了哪些修改。

![](/assets/posts/CMU15445-Refs/p3/17.png)  
![](/assets/posts/CMU15445-Refs/p3/18.png)  

如果你需要提交/推送，点击 Git ，点击提交

![](/assets/posts/CMU15445-Refs/p3/19.png)  

点击提交并推送即可。如果需要合并分支，可以点击分支，随后签出过去，然后点击合并，选择想要的分支合并即可。比如：我在 p3 分支上完成项目，当我完成后，我签出到我的 master 分支，然后合并 p3 分支。


## 知识补充  

课上因为时间短暂，Andy 并没有详细的展开讲模型的优缺点 (或许这部分在 15721 里？) 这里进行一些补充。

1. 火山模型的优点与缺点

这个模型应用非常广泛，优点也很显然：每个 Executor 都被抽象成独立的个体，只需要关注当前 Executor 的逻辑实现。但它也有几个缺点：

- 大量的虚函数调用：我们每调用一次 Next 就对应一次虚函数调用，这会造成不小的性能开销。
- 在每一个 Next 调用中，又嵌套着一层层的 子Next 调用，也就是说每次 Next 都要经过大量的代码段，这无疑会对缓存造成影响：无论是高速缓存还是 TLB 等等。

这两个缺点在以前的年代是不值一提的，火山模型是在 90 年代提出的，当时数据库的主要 bottleneck 是 IO 而且内存不够。如今随着储存速度越来越快，很多数据都可以跑到内存上，这时火山模型的效率就捉襟见肘了。这也是为什么向量化流行的原因，它能对缓存，分支预测等起到很好的保护作用。

不过，**对于 OLTP 来说，火山模型就够了**，毕竟一次 Query 的 Tuple 数量不大。

2. 向量化模型

一次取一堆数据，适用于 OLAP

考虑 `SELECT SUM(age) FROM students` ，对于火山模型，我们一次取一个 Tuple ，所以正如我们程序所写的，我们最后是 a+b 的形式。而向量化模型是 a[] + b[] 的形式，数组加数组是非常方便优化的，不论是 编译器 层面还是 CPU 层面，方便进行并行计算。

并且我们一次可以拿更多数据到内存，从而在内存上计算。


## 推荐阅读  

这篇文章大致讲述了 火山模型 与 向量化模型 的优缺点：[https://zhuanlan.zhihu.com/p/100933389](https://zhuanlan.zhihu.com/p/100933389)

这篇文章很好的解释了论文，分析了火山模型的缺点：[https://zhuanlan.zhihu.com/p/587568943](https://zhuanlan.zhihu.com/p/587568943)


## Optional Leaderboard Tasks  

**由于是 Leaderboard，所以并不会详细说我是怎么做的**

Bustub 允许我们精益求精，实现额外的优化准则。在实现这部分之前，我先把所有的 optimizer 下的优化规则阅读了一遍：

- `merge_filter_nlj.cpp` ：当 nlj 谓词为 true，将谓词融入 NLJ
- `merge_projection.cpp` ：当且仅当投影的列和下面的列顺序一致且类型一致，直接去掉投影
- `merge_filter_scan.cpp` ：将 filter 谓词融入 SeqScan 中。这部分需要额外的改写，改写完 SeqScan 后，类似 `SELECT * FROM test_2 WHERE colA=2;` 这样的语句只需要一层就能解决了。

![](/assets/posts/CMU15445-Refs/p3/20.png)  

这些优化规则中最需要理解的我认为是：`merge_filter_nlj.cpp`其中涉及对列序号的改写，并且在什么时候 merge 也有一定的讲究。

接下来开始针对着写优化：

### Q1  

完成 Q1 首先要求我们完成对应的计划，其中有很多难点，解决的方式很灵活。但首先要明确一点，就是 Bustub 只支持一个或两个整数的索引，所以我们不用写的太复杂。

- 对于如何提取索引列，我是对 Filter Predicate 构建哈希表，随后拿索引的列在哈希表中查找
- 对于如何构造索引的 Key，我们需要使用 `SetFromKey()`方法。我们根据 Value 构造出 Tuple，这个 Tuple 的 Schema 不重要，可以随便找个 Schema 然后用 `CopySchema()`
- 在改写规则的时候会依据索引的名字从表中拿idx ，需要注意即使是同一列 索引拿到的 Name 和 Schema 中的 Name 也是不一样的。

```cpp
// Index name: x, table_col_name: t1.x
uint32_t index_idx = seq_plan.output_schema_->GetColIdx(seq_plan.table_name_ + "." + index_column.GetName());

```

### Q2  

谓词下推没有我想的简单，连续肝了五六个小时才做完。

谓词下推中比较复杂的就是**列下标的转换**和**遍历方式的改变**。

首先，我们原先所有的优化规则用的都是后序遍历，也就是由下向上的遍历，这样的话，谓词就只能下推一层。所以我们必须使用前序遍历，将应有的谓词尽可能的推到下层节点。

例如下图的四表 Join，基本每个条件都下推到了应在的位置，标号也都是一一对应的。

![](/assets/posts/CMU15445-Refs/p3/21.png)  

列下标的转换的处理很灵活，各有不同，建议结合 `merge_filter_nlj.cpp`中对列的重写一起思考。

在跑这个例子的时候发现测评的机子是真的好，比我的虚拟机快了10倍。。这个 Q2 也是整个 CMU15445 最令我印象深刻的。原本我的机器跑 10 分钟都跑不出 1 遍，优化完后 几分钟就能 跑 10 遍。这真切的让我感受到算法是真的有用的。

最后还留下点思考：我们都知道 Join 表的左侧应该是小表，这样性能才更高。

**那如何判断两张表大小呢?** 如果直接比较两张表的行数显然是不行的，因为还需要考虑 Filter 可能对其中一张表进行过滤。我认为或许可以使用 选择率 来解决，根据 选择率 来决定哪张表小。

### Q3  

> SELECT v, d1, d2 FROM (  
> SELECT v,  
> MAX(v1) AS d1, MIN(v1), MAX(v2), MIN(v2),  
> MAX(v1) + MIN(v1), MAX(v2) + MIN(v2),  
> MAX(v1) + MAX(v1) + MAX(v2) AS d2  
> FROM t7 LEFT JOIN (SELECT v4 FROM t8 WHERE 1 == 2) ON v < v4  
> GROUP BY v  
> );

首先我们看到 Join 的右节点的条件恒为 False，于是我们可以增加一条规则来提前计算 恒为错的 Filter，直接将其优化为 0 行的表，这样就无需 Join 了。

对于聚集函数的投影，下面这个问题解决了我的疑惑，有聚集函数的投影不能带有除了 group-by 属性之外的非聚集属性。

[https://stackoverflow.com/questions/5920070/why-cant-you-mix-aggregate-values-and-non-aggregate-values-in-a-single-select](https://stackoverflow.com/questions/5920070/why-cant-you-mix-aggregate-values-and-non-aggregate-values-in-a-single-select)

剩余的就是将不需要的聚集函数给优化掉了。因为有 group-by 列，所以我这里的实现比较丑陋，重构了几个 schema 之后才解决这个问题。这里的实现非常自由，而我的实现是有一定局限性的。比如：如果 group-by 中出现了 v1 + v2 + v3 这样的式子，或许我的算子就会出错了。后续可能会阅读好的数据库源码来学习一下该怎么写。

最后时间也是比我原先快了不少，不过我对 Q1 做到 1 是很疑惑的？不知道有什么奇淫巧技在里面。

![](/assets/posts/CMU15445-Refs/p3/22.png)  

从 4000 到 400 的飞跃


## 最后  

因为本地测试和远程测试一样，所以可以很快速的响应错误了。总的来说，相比于原来只会写一些简单的 SQL 语句，对数据库的了解更深了。

<del>至于剩下的优化，后续有时间会补上，大致看了一下，似乎是要做**谓词下推**等进一步的优化，这部分应该很有意思。</del>

![](/assets/posts/CMU15445-Refs/p3/23.png)  